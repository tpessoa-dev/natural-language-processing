{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula 2-6 IA PLN - Demo.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdelQOET5rDj"
      },
      "source": [
        "#**Processamento de Linguagem Natural**\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VaLZoauH4KXg"
      },
      "source": [
        "## DOCUMENTO / CORPUS\n",
        "\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d4CKjpwJ2DD2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "12ceffe9-b05c-4f7e-c275-8345f2a8f250"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Documento e Corpus\n",
        "df = pd.DataFrame({\n",
        "    'text': [\n",
        "      'Sobre MBA? Eu gostei muito do MBA da FIAP',\n",
        "      'O MBA da FIAP pode melhorar, não gostei muito'\n",
        "    ],\n",
        "    'class': [\n",
        "        'positivo',\n",
        "        'negativo'\n",
        "    ]})\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Sobre MBA? Eu gostei muito do MBA da FIAP</td>\n",
              "      <td>positivo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>O MBA da FIAP pode melhorar, não gostei muito</td>\n",
              "      <td>negativo</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            text     class\n",
              "0      Sobre MBA? Eu gostei muito do MBA da FIAP  positivo\n",
              "1  O MBA da FIAP pode melhorar, não gostei muito  negativo"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x3Kb4Wb2elpd"
      },
      "source": [
        "## TOKENIZAÇÃO\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WZoqP0WKfm2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c09a14f-a027-48bc-8f7b-af38d16aee0c"
      },
      "source": [
        "# aplica em uma string\n",
        "from nltk.tokenize import word_tokenize\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "nome = 'Anderson Vieira Dourado'\n",
        "\n",
        "print(word_tokenize(nome))\n",
        "print(nome.split(' '))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "['Anderson', 'Vieira', 'Dourado']\n",
            "['Anderson', 'Vieira', 'Dourado']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iA79KVRcg2Di",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d4de6b3-c72b-411b-ca9e-dfe0e2091ae0"
      },
      "source": [
        "# Aplica em uma lista\n",
        "texto = ['Anderson Vieira Dourado','um dois, três']\n",
        "type(texto)\n",
        "\n",
        "# usando o split\n",
        "print(texto[1].split())\n",
        "[t.split() for t in texto]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['um', 'dois,', 'três']\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Anderson', 'Vieira', 'Dourado'], ['um', 'dois,', 'três']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXRuWWdjkZtr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4df14494-cfbe-4bd1-e569-9977c6844dca"
      },
      "source": [
        "#from nltk.tokenize import word_tokenize\n",
        "#import nltk\n",
        "#nltk.download('punkt')\n",
        "\n",
        "[word_tokenize(t) for t in texto]"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['Anderson', 'Vieira', 'Dourado'], ['um', 'dois', ',', 'três']]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weMWMKoGljZx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "017c7b60-525c-448f-b91a-190185ed3c58"
      },
      "source": [
        "# Em um dataframe\n",
        "#from nltk.tokenize import word_tokenize\n",
        "#import nltk\n",
        "#nltk.download('punkt')\n",
        "\n",
        "print(df.text.apply(word_tokenize))\n",
        "\n",
        "df['tokens'] = df.text.apply(word_tokenize)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    [Sobre, MBA, ?, Eu, gostei, muito, do, MBA, da...\n",
            "1    [O, MBA, da, FIAP, pode, melhorar, ,, não, gos...\n",
            "Name: text, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9ws_prkmJUz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5abfa304-a8f2-4410-a8a0-6e5b697d26e4"
      },
      "source": [
        "# Em uma sentança (representada pelo ponto final)\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "\n",
        "s = 'Anderson Vieira.\\nDourado'\n",
        "\n",
        "print(sent_tokenize(s))\n",
        "print([word_tokenize(t) for t in sent_tokenize(s)])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['Anderson Vieira.', 'Dourado']\n",
            "[['Anderson', 'Vieira', '.'], ['Dourado']]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAo3WqWhjfg1"
      },
      "source": [
        "#from nltk.tokenize import wordpunct_tokenize (separa por qualquer pontuação, inclusive números R$3,50 = 'R','$','3',',','50')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqCkOL0C5-FC"
      },
      "source": [
        "## UNIGRAMA\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rhnMqaq6Bgc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d00d50cb-43ad-4aff-8e9b-b05cfa2aeb57"
      },
      "source": [
        "df.text"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0        Sobre MBA? Eu gostei muito do MBA da FIAP\n",
              "1    O MBA da FIAP pode melhorar, não gostei muito\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6kSv69h2jKs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d3fbafeb-f34d-452c-d299-ea80f53d015d"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(1,1))\n",
        "vect.fit(df.text)\n",
        "text_vect = vect.transform(df.text)\n",
        "\n",
        "print(pd.DataFrame(text_vect.A, columns=vect.get_feature_names()).to_string())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   da  do  eu  fiap  gostei  mba  melhorar  muito  não  pode  sobre\n",
            "0   1   1   1     1       1    2         0      1    0     0      1\n",
            "1   1   0   0     1       1    1         1      1    1     1      0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DqaSvPft7oMJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "728ed3e7-3892-4d88-f46b-7484a8d88652"
      },
      "source": [
        "text_vect"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<2x11 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 16 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHfqBTzH6LQm"
      },
      "source": [
        "## BIGRAMA\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDLdamcR2q4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f1cc67-92a0-4d46-dcf3-c7ea1a3a62fb"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(2,2))\n",
        "vect.fit(df.text)\n",
        "text_vect = vect.transform(df.text)\n",
        "\n",
        "print(pd.DataFrame(text_vect.A, columns=vect.get_feature_names()).to_string())"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "   da fiap  do mba  eu gostei  fiap pode  gostei muito  mba da  mba eu  melhorar não  muito do  não gostei  pode melhorar  sobre mba\n",
            "0        1       1          1          0             1       1       1             0         1           0              0          1\n",
            "1        1       0          0          1             1       1       0             1         0           1              1          0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIFnNUdM6SvU"
      },
      "source": [
        "## TRIGRAMA\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xalnPjjG2u7k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "18ab5a4a-82b1-42bd-94c9-fbabb1d11e96"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(3,3))\n",
        "vect.fit(df.text)\n",
        "text_vect = vect.transform(df.text)\n",
        "\n",
        "print(pd.DataFrame(text_vect.A, columns=vect.get_feature_names()).T.to_string())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                     0  1\n",
            "da fiap pode         0  1\n",
            "do mba da            1  0\n",
            "eu gostei muito      1  0\n",
            "fiap pode melhorar   0  1\n",
            "gostei muito do      1  0\n",
            "mba da fiap          1  1\n",
            "mba eu gostei        1  0\n",
            "melhorar não gostei  0  1\n",
            "muito do mba         1  0\n",
            "não gostei muito     0  1\n",
            "pode melhorar não    0  1\n",
            "sobre mba eu         1  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "swmx7vR65mdb"
      },
      "source": [
        "## REGEX\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9YlTu0v36jmy"
      },
      "source": [
        "email = \"dourado@gmail.com\""
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0DLpiJZvUT86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c1d4ebaf-4f3b-432c-d60a-0ca99047057d"
      },
      "source": [
        "# função split do Python\n",
        "email.split(\"@\")[1].split(\".\")[0]\n",
        "\n",
        "#\"dourado@gmail.com\".split(\"@\")[1].split('.')[0]"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'gmail'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLP8WEzi_i7j",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "28d85a32-c9f0-4bfb-d5d3-03ed338605ef"
      },
      "source": [
        "\"dourado @ gmail . com\".split(\"@\")[1].split(\".\")[0]"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' gmail '"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSUYkTSFEK7l",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1ffafb7-269b-4cf6-9252-0d13ca5edc80"
      },
      "source": [
        "# importa pacote de regular expression\n",
        "import re\n",
        "\n",
        "regex = r\"(?<=@)[^.]+(?=\\.)\"\n",
        "re.findall(regex, email)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['gmail']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oP7VTbtgDkYq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4aa6dbe5-ff69-4af6-aa34-56877ff2bc04"
      },
      "source": [
        "# mede o tempo de execução de um trecho de código\n",
        "import timeit\n",
        "\n",
        "timeit.Timer(\n",
        " 're.findall(regex, \"dourado@gmail.com\")',\n",
        " 'import re; regex = r\"(?<=@)[^.]+(?=\\.)\"'\n",
        ").repeat(2)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.251617834000001, 1.2387737389999955]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBmaBfknD0l7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "273a65a3-0a88-4234-d943-4f4f502b39c4"
      },
      "source": [
        "import timeit\n",
        "\n",
        "timeit.Timer(\n",
        " '\"dourado@gmail.com\".split(\"@\")[1].split(\".\")[0]'\n",
        ").repeat(2)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3680243539999992, 0.3791753710000023]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u_0q3goBYfGJ"
      },
      "source": [
        "import antigravity\n",
        "\n",
        "#Abrir o site: https://xkcd.com/353/"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OiOFT26cD-W6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d22511a7-dff9-4215-8b49-472d7172de5c"
      },
      "source": [
        "import this"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Zen of Python, by Tim Peters\n",
            "\n",
            "Beautiful is better than ugly.\n",
            "Explicit is better than implicit.\n",
            "Simple is better than complex.\n",
            "Complex is better than complicated.\n",
            "Flat is better than nested.\n",
            "Sparse is better than dense.\n",
            "Readability counts.\n",
            "Special cases aren't special enough to break the rules.\n",
            "Although practicality beats purity.\n",
            "Errors should never pass silently.\n",
            "Unless explicitly silenced.\n",
            "In the face of ambiguity, refuse the temptation to guess.\n",
            "There should be one-- and preferably only one --obvious way to do it.\n",
            "Although that way may not be obvious at first unless you're Dutch.\n",
            "Now is better than never.\n",
            "Although never is often better than *right* now.\n",
            "If the implementation is hard to explain, it's a bad idea.\n",
            "If the implementation is easy to explain, it may be a good idea.\n",
            "Namespaces are one honking great idea -- let's do more of those!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poR8p3MAKOIG"
      },
      "source": [
        "    Bonito é melhor que feio.\n",
        "    Explícito é melhor que implícito.\n",
        "    Simples é melhor que Complexo.\n",
        "    Complexo é melhor que complicado.\n",
        "    Achatado é melhor que aninhado.\n",
        "    Disperso é melhor que compacto.\n",
        "    Legibilidade conta.\n",
        "    Casos especiais não são especiais o suficiente para quebrar as regras.\n",
        "    Apesar de praticidade vencer a pureza.\n",
        "    Erros nunca devem passar despercebidos.\n",
        "    A menos que passem explicitamente \"despercebidos\".\n",
        "    Diante de ambiguidades, recuse a tentação de deduzir.\n",
        "    Deve haver uma --e preferencialmente só uma-- maneira fácil de fazer isto.\n",
        "    Apesar de que a maneira não pode ser óbvia de primeira, a não ser que você seja \"asiático\".\n",
        "    Agora é melhor do que nunca.\n",
        "    Porém, muitas vezes nunca é melhor do que *agora*.\n",
        "    Se a implementação é difícil de explicar, é uma péssima ideia.\n",
        "    Se a implementação é fácil de explicar, pode ser uma boa ideia.\n",
        "    Namespaces são uma grande ideia gritante -- vamos fazer mais dessas!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzrIMF-vkQUW"
      },
      "source": [
        "Caracteres ou metacaracteres\n",
        "\n",
        "    meta - O que faz?\n",
        "    ---------------------\n",
        "    . - Qualquer caractere\n",
        "    [] - Lista de caracteres\n",
        "    [^] - Lista negada\n",
        "    ? - Anterior pode existir ou não\n",
        "    .* - Qualquer coisa\n",
        "    {x} - Anterior aparece x vezes\n",
        "    $ - Fim da linha\n",
        "    + - Anterior ao menos ums vez\n",
        "    (xy) - Cria grupos\n",
        "    ^ - Começo da linha\n",
        "    \\ - escapa o meta (ignora)\n",
        "    | - ou\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UHiGfhPskQDH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33613244-04e9-42c7-f35f-fa3778c1acbc"
      },
      "source": [
        "import re\n",
        "#email\n",
        "re.findall(r'.',email)\n",
        "re.findall(r'[a-z]',email)\n",
        "re.findall(r'[0-9]',email)\n",
        "re.findall(r'.*',email)\n",
        "re.findall(r'$',email)\n",
        "\n",
        "re.findall(r'[a-z]+',email)\n",
        "\n",
        "re.findall(r'^.',email)\n",
        "re.findall(r'^d',email)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['d']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSK6DZRdmKo8"
      },
      "source": [
        "## STOPWORDS"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp5M3u_XrGqY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7196b2da-c194-47c0-80e1-ee0cd9796f43"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "\n",
        "stops = nltk.corpus.stopwords.words('english')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IB8EYOCU9--r",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "f59ae3af-922f-4315-ab8a-628ed08fc5a4"
      },
      "source": [
        "# remove uma stopword da lista\n",
        "stops.pop(3)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'myself'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-gT5nMg91FW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc93feba-1533-4fd5-fbb0-6db3764f0d95"
      },
      "source": [
        "# lista as 10 primeiras stopwords\n",
        "stops[:10]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i', 'me', 'my', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\"]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GoE1kJ6UZ_oA"
      },
      "source": [
        "# podemos criar nossa propria lista\n",
        "stops = stops + [\"anderson\", \"fiap\"]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3vvZzFQS9zjq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aea66c28-3cb9-46e2-cdd9-8838cce0f3d0"
      },
      "source": [
        "# lista todas as stopwords\n",
        "stops"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i',\n",
              " 'me',\n",
              " 'my',\n",
              " 'we',\n",
              " 'our',\n",
              " 'ours',\n",
              " 'ourselves',\n",
              " 'you',\n",
              " \"you're\",\n",
              " \"you've\",\n",
              " \"you'll\",\n",
              " \"you'd\",\n",
              " 'your',\n",
              " 'yours',\n",
              " 'yourself',\n",
              " 'yourselves',\n",
              " 'he',\n",
              " 'him',\n",
              " 'his',\n",
              " 'himself',\n",
              " 'she',\n",
              " \"she's\",\n",
              " 'her',\n",
              " 'hers',\n",
              " 'herself',\n",
              " 'it',\n",
              " \"it's\",\n",
              " 'its',\n",
              " 'itself',\n",
              " 'they',\n",
              " 'them',\n",
              " 'their',\n",
              " 'theirs',\n",
              " 'themselves',\n",
              " 'what',\n",
              " 'which',\n",
              " 'who',\n",
              " 'whom',\n",
              " 'this',\n",
              " 'that',\n",
              " \"that'll\",\n",
              " 'these',\n",
              " 'those',\n",
              " 'am',\n",
              " 'is',\n",
              " 'are',\n",
              " 'was',\n",
              " 'were',\n",
              " 'be',\n",
              " 'been',\n",
              " 'being',\n",
              " 'have',\n",
              " 'has',\n",
              " 'had',\n",
              " 'having',\n",
              " 'do',\n",
              " 'does',\n",
              " 'did',\n",
              " 'doing',\n",
              " 'a',\n",
              " 'an',\n",
              " 'the',\n",
              " 'and',\n",
              " 'but',\n",
              " 'if',\n",
              " 'or',\n",
              " 'because',\n",
              " 'as',\n",
              " 'until',\n",
              " 'while',\n",
              " 'of',\n",
              " 'at',\n",
              " 'by',\n",
              " 'for',\n",
              " 'with',\n",
              " 'about',\n",
              " 'against',\n",
              " 'between',\n",
              " 'into',\n",
              " 'through',\n",
              " 'during',\n",
              " 'before',\n",
              " 'after',\n",
              " 'above',\n",
              " 'below',\n",
              " 'to',\n",
              " 'from',\n",
              " 'up',\n",
              " 'down',\n",
              " 'in',\n",
              " 'out',\n",
              " 'on',\n",
              " 'off',\n",
              " 'over',\n",
              " 'under',\n",
              " 'again',\n",
              " 'further',\n",
              " 'then',\n",
              " 'once',\n",
              " 'here',\n",
              " 'there',\n",
              " 'when',\n",
              " 'where',\n",
              " 'why',\n",
              " 'how',\n",
              " 'all',\n",
              " 'any',\n",
              " 'both',\n",
              " 'each',\n",
              " 'few',\n",
              " 'more',\n",
              " 'most',\n",
              " 'other',\n",
              " 'some',\n",
              " 'such',\n",
              " 'no',\n",
              " 'nor',\n",
              " 'not',\n",
              " 'only',\n",
              " 'own',\n",
              " 'same',\n",
              " 'so',\n",
              " 'than',\n",
              " 'too',\n",
              " 'very',\n",
              " 's',\n",
              " 't',\n",
              " 'can',\n",
              " 'will',\n",
              " 'just',\n",
              " 'don',\n",
              " \"don't\",\n",
              " 'should',\n",
              " \"should've\",\n",
              " 'now',\n",
              " 'd',\n",
              " 'll',\n",
              " 'm',\n",
              " 'o',\n",
              " 're',\n",
              " 've',\n",
              " 'y',\n",
              " 'ain',\n",
              " 'aren',\n",
              " \"aren't\",\n",
              " 'couldn',\n",
              " \"couldn't\",\n",
              " 'didn',\n",
              " \"didn't\",\n",
              " 'doesn',\n",
              " \"doesn't\",\n",
              " 'hadn',\n",
              " \"hadn't\",\n",
              " 'hasn',\n",
              " \"hasn't\",\n",
              " 'haven',\n",
              " \"haven't\",\n",
              " 'isn',\n",
              " \"isn't\",\n",
              " 'ma',\n",
              " 'mightn',\n",
              " \"mightn't\",\n",
              " 'mustn',\n",
              " \"mustn't\",\n",
              " 'needn',\n",
              " \"needn't\",\n",
              " 'shan',\n",
              " \"shan't\",\n",
              " 'shouldn',\n",
              " \"shouldn't\",\n",
              " 'wasn',\n",
              " \"wasn't\",\n",
              " 'weren',\n",
              " \"weren't\",\n",
              " 'won',\n",
              " \"won't\",\n",
              " 'wouldn',\n",
              " \"wouldn't\",\n",
              " 'anderson',\n",
              " 'fiap']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VI2P65ED96Vp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0388f5d-33d8-40f5-ffc0-4e465e466e65"
      },
      "source": [
        "len(stops)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "180"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhi1oSyK6ekI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "351c8fe7-0de3-49b1-bcd5-9a883687cc83"
      },
      "source": [
        "# Aplicando a utilização das stopwords\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "stops = nltk.corpus.stopwords.words('portuguese') + [\"fiap\"]\n",
        "\n",
        "vect = CountVectorizer(ngram_range=(1,1), stop_words=stops)\n",
        "vect.fit(df.text)\n",
        "text_vect = vect.transform(df.text)\n",
        "\n",
        "print(pd.DataFrame(text_vect.A, columns=vect.get_feature_names()).T.to_string())"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "          0  1\n",
            "gostei    1  1\n",
            "mba       2  1\n",
            "melhorar  0  1\n",
            "pode      0  1\n",
            "sobre     1  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niXXv3e-6kb0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c66ac63-b8ea-48a7-d9cd-81a28aa870f9"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc4YJdb96m5z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cfd5fd10-44cf-48a1-e385-99a0a667051a"
      },
      "source": [
        "print(nltk.corpus.stopwords.words('portuguese')[:10])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['de', 'a', 'o', 'que', 'e', 'é', 'do', 'da', 'em', 'um']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dj6gDOA2bxWO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7618a8e9-330a-4337-8b46-ac9ec3e471cb"
      },
      "source": [
        "len(stops)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Y9kNz9WXUDP"
      },
      "source": [
        "## PART-OF-SPEECH TAGGER (POS-Tag)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sXlbSKvRBr4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c9f428f-cd23-498e-9303-473c8a891ab7"
      },
      "source": [
        "# Tokenizxação\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.tag import pos_tag\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')\n",
        "\n",
        "doc = word_tokenize(\"John's big idea isn't all that bad.\")\n",
        "doc_tag = pos_tag(doc)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/universal_tagset.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oqqNTNCABrwk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c61a464-80b6-4513-fca3-0fa371581218"
      },
      "source": [
        "pos_tag(word_tokenize(\"John's big idea isn't all that bad.\"),tagset='universal')"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('John', 'NOUN'),\n",
              " (\"'s\", 'PRT'),\n",
              " ('big', 'ADJ'),\n",
              " ('idea', 'NOUN'),\n",
              " ('is', 'VERB'),\n",
              " (\"n't\", 'ADV'),\n",
              " ('all', 'DET'),\n",
              " ('that', 'DET'),\n",
              " ('bad', 'ADJ'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oh60rZ8NIijA"
      },
      "source": [
        "De/Para do POS Tag com o tagset='universal':\n",
        "\n",
        "- NOUN (nouns / substantivos)\n",
        "- VERB (verbs / verbos)\n",
        "- ADJ (adjectives / adjetivos)\n",
        "- ADV (adverbs / advérbios)\n",
        "- PRON (pronouns / pronomes)\n",
        "- DET (determiners and articles / determinantes e artigos)\n",
        "- ADP (adpositions - prepositions and postpositions / adições - preposições e postposições)\n",
        "- NUM (numerals / numerais)\n",
        "- CONJ (conjunctions / conjunções)\n",
        "- PRT (particles / partículas)\n",
        "- . (punctuation marks / sinais de pontuação)\n",
        "- X (a catch-all for other categories such as abbreviations or foreign words / um exemplo geral para outras categorias, como abreviações ou palavras estrangeiras)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lEkLwe40E71L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f98ca2c6-e352-41e2-89a9-8f6066761c62"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('universal_tagset')"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package universal_tagset to /root/nltk_data...\n",
            "[nltk_data]   Package universal_tagset is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AVtgwMEBk-M",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "outputId": "647a0aad-b1b7-472d-ac9f-525ba7e8366e"
      },
      "source": [
        "# Tokenizxação\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "#df['tokens'] = df.text.apply(word_tokenize)\n",
        "df[[\"tokens\",\"text\"]]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tokens</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Sobre, MBA, ?, Eu, gostei, muito, do, MBA, da...</td>\n",
              "      <td>Sobre MBA? Eu gostei muito do MBA da FIAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[O, MBA, da, FIAP, pode, melhorar, ,, não, gos...</td>\n",
              "      <td>O MBA da FIAP pode melhorar, não gostei muito</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              tokens                                           text\n",
              "0  [Sobre, MBA, ?, Eu, gostei, muito, do, MBA, da...      Sobre MBA? Eu gostei muito do MBA da FIAP\n",
              "1  [O, MBA, da, FIAP, pode, melhorar, ,, não, gos...  O MBA da FIAP pode melhorar, não gostei muito"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aRuCY82SXnQV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7222ab06-cab4-4427-ef18-127fabeaa783"
      },
      "source": [
        "# Rotular parte do discurso\n",
        "from nltk.tag import pos_tag\n",
        "\n",
        "df['tags'] = df.tokens.apply(pos_tag, tagset='universal')\n",
        "df.tags[1]"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('O', 'NOUN'),\n",
              " ('MBA', 'NOUN'),\n",
              " ('da', 'NOUN'),\n",
              " ('FIAP', 'NOUN'),\n",
              " ('pode', 'NOUN'),\n",
              " ('melhorar', 'NOUN'),\n",
              " (',', '.'),\n",
              " ('não', 'ADJ'),\n",
              " ('gostei', 'NOUN'),\n",
              " ('muito', 'NOUN')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    }
  ]
}